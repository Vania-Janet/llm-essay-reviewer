# Essay Evaluator - AI-Powered Academic Essay Assessment System

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)
[![LangChain](https://img.shields.io/badge/LangChain-Latest-green.svg)](https://langchain.com/)
[![OpenAI](https://img.shields.io/badge/OpenAI-GPT--4-orange.svg)](https://openai.com/)
[![Flask](https://img.shields.io/badge/Flask-3.0+-red.svg)](https://flask.palletsprojects.com/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

An intelligent, automated academic essay evaluation system powered by GPT-4, LangGraph, and LangChain. This system provides comprehensive, multi-criteria assessment of academic essays with detailed feedback and professional reporting.

---

## ğŸ“‹ Table of Contents

- [Features](#-features)
- [Project Structure](#-project-structure)
- [Installation](#-installation)
- [Quick Start](#-quick-start)
- [Usage](#-usage)
- [Configuration](#-configuration)
- [API Documentation](#-api-documentation)
- [Development](#-development)
- [Testing](#-testing)
- [Contributing](#-contributing)
- [License](#-license)

---

## âœ¨ Features

### Core Capabilities
- **Multi-Criteria Evaluation**: 6 rigorous academic criteria with weighted scoring
- **AI-Powered Analysis**: GPT-4 with structured outputs for precise evaluations
- **PDF Processing**: Intelligent extraction and cleaning of essay documents
- **Batch Processing**: Evaluate multiple essays simultaneously
- **Professional Reports**: Generate detailed HTML/PDF evaluation reports
- **Comparison Tools**: Side-by-side analysis of multiple essays
- **Statistics Dashboard**: Visual analytics with Chart.js

### Web Interface
- **Modern UI**: Clean, responsive design with drag-and-drop upload
- **User Authentication**: Secure JWT-based authentication
- **Essay Library**: Browse, search, and manage evaluated essays
- **Interactive Chat**: Ask questions about essays and evaluations
- **Real-time Processing**: Progress indicators for batch evaluations
- **Export Capabilities**: Download results as Excel/CSV

### Evaluation Criteria

| Criterion | Weight | Description |
|-----------|--------|-------------|
| **Technical Quality** | 16.7% | Structure, coherence, and academic rigor |
| **Creativity** | 16.7% | Innovation and original thinking |
| **Thematic Alignment** | 16.7% | Relevance to contest themes |
| **Social Responsibility** | 16.7% | Ethical and sustainability considerations |
| **AI Usage** | 16.7% | Responsible and reflective use of AI tools |
| **Impact Potential** | 16.7% | Publication quality and potential influence |

**Scoring**: Each criterion scored 1-5 with detailed justification

---

## ğŸ“ Project Structure

```
essay-agent/
â”œâ”€â”€ essay_evaluator/              # Main application package
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ core/                     # Core business logic
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ agent/                # LangGraph agent
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ evaluator.py     # Main evaluation agent
â”‚   â”‚   â”‚   â””â”€â”€ graph.py         # Graph construction
â”‚   â”‚   â”œâ”€â”€ evaluation/           # Evaluation logic
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ criteria.py      # Criterion evaluators
â”‚   â”‚   â”‚   â””â”€â”€ prompts.py       # LLM prompts
â”‚   â”‚   â””â”€â”€ models/               # Data models
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”œâ”€â”€ essay.py         # Essay models
â”‚   â”‚       â””â”€â”€ evaluation.py    # Evaluation models
â”‚   â”‚
â”‚   â”œâ”€â”€ api/                      # REST API
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ app.py               # Flask application
â”‚   â”‚   â”œâ”€â”€ routes/              # API endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ auth.py          # Authentication
â”‚   â”‚   â”‚   â”œâ”€â”€ essays.py        # Essay operations
â”‚   â”‚   â”‚   â””â”€â”€ evaluation.py   # Evaluation endpoints
â”‚   â”‚   â””â”€â”€ middleware/          # API middleware
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”œâ”€â”€ auth.py          # JWT verification
â”‚   â”‚       â””â”€â”€ error_handlers.py
â”‚   â”‚
â”‚   â”œâ”€â”€ web/                      # Web interface
â”‚   â”‚   â”œâ”€â”€ static/              # Static assets
â”‚   â”‚   â”‚   â”œâ”€â”€ css/
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ styles.css
â”‚   â”‚   â”‚   â”œâ”€â”€ js/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ script.js
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ criteria-management.js
â”‚   â”‚   â”‚   â””â”€â”€ images/
â”‚   â”‚   â”‚       â”œâ”€â”€ icon.png
â”‚   â”‚   â”‚       â””â”€â”€ logo.png
â”‚   â”‚   â””â”€â”€ templates/           # HTML templates
â”‚   â”‚       â”œâ”€â”€ index.html
â”‚   â”‚       â””â”€â”€ login.html
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/                    # Utility modules
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ pdf/                 # PDF processing
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ extractor.py    # PDF text extraction
â”‚   â”‚   â”‚   â””â”€â”€ cleaner.py      # Text cleaning
â”‚   â”‚   â”œâ”€â”€ database/            # Database utilities
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ connection.py   # DB connection
â”‚   â”‚   â”‚   â””â”€â”€ operations.py   # CRUD operations
â”‚   â”‚   â””â”€â”€ validators.py       # Input validation
â”‚   â”‚
â”‚   â”œâ”€â”€ data/                     # Data storage
â”‚   â”‚   â”œâ”€â”€ raw/                 # Raw uploaded PDFs
â”‚   â”‚   â”œâ”€â”€ processed/           # Processed texts
â”‚   â”‚   â””â”€â”€ database/            # SQLite database
â”‚   â”‚       â””â”€â”€ essays.db
â”‚   â”‚
â”‚   â””â”€â”€ tests/                    # Test suite
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ test_agent.py
â”‚       â”œâ”€â”€ test_api.py
â”‚       â”œâ”€â”€ test_pdf_processor.py
â”‚       â””â”€â”€ fixtures/
â”‚
â”œâ”€â”€ scripts/                      # Utility scripts
â”‚   â”œâ”€â”€ load_processed_essays.py # Migrate existing data
â”‚   â”œâ”€â”€ setup_database.py       # Initialize database
â”‚   â””â”€â”€ batch_evaluate.py       # Batch processing
â”‚
â”œâ”€â”€ docs/                         # Documentation
â”‚   â”œâ”€â”€ architecture/            # Architecture docs
â”‚   â”‚   â”œâ”€â”€ system_design.md
â”‚   â”‚   â””â”€â”€ data_flow.md
â”‚   â”œâ”€â”€ api/                     # API documentation
â”‚   â”‚   â””â”€â”€ endpoints.md
â”‚   â””â”€â”€ user_guide/              # User guides
â”‚       â”œâ”€â”€ getting_started.md
â”‚       â””â”€â”€ admin_guide.md
â”‚
â”œâ”€â”€ config/                       # Configuration files
â”‚   â”œâ”€â”€ development.py
â”‚   â”œâ”€â”€ production.py
â”‚   â””â”€â”€ testing.py
â”‚
â”œâ”€â”€ .env.example                  # Environment variables template
â”œâ”€â”€ .gitignore                    # Git ignore rules
â”œâ”€â”€ requirements.txt              # Python dependencies
â”œâ”€â”€ requirements-dev.txt          # Development dependencies
â”œâ”€â”€ setup.py                      # Package installation
â”œâ”€â”€ pytest.ini                    # Pytest configuration
â”œâ”€â”€ README.md                     # This file
â””â”€â”€ LICENSE                       # License file
```

---

## ğŸš€ Installation

### Prerequisites

- Python 3.8 or higher
- pip package manager
- OpenAI API key
- (Optional) Redis for caching

### Step 1: Clone the Repository

```bash
git clone https://github.com/Vania-Janet/llm-essay-reviewer.git
cd llm-essay-reviewer
```

### Step 2: Create Virtual Environment

```bash
# Create virtual environment
python -m venv .venv

# Activate virtual environment
# On macOS/Linux:
source .venv/bin/activate
# On Windows:
.venv\Scripts\activate
```

### Step 3: Install Dependencies

```bash
# Install core dependencies
pip install -r requirements.txt

# Install development dependencies (optional)
pip install -r requirements-dev.txt
```

### Step 4: Configure Environment

```bash
# Copy environment template
cp .env.example .env

# Edit .env with your settings
nano .env  # or use your preferred editor
```

Required environment variables:
```env
# OpenAI Configuration
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-4o

# Database
DATABASE_URL=sqlite:///essay_evaluator/data/database/essays.db

# Flask Configuration
FLASK_SECRET_KEY=your_secret_key_here
FLASK_ENV=development

# JWT Authentication
JWT_SECRET_KEY=your_jwt_secret_here
JWT_ACCESS_TOKEN_EXPIRES=3600

# Upload Settings
UPLOAD_FOLDER=essay_evaluator/data/raw
MAX_UPLOAD_SIZE=10485760  # 10MB

# Optional: Redis Cache
REDIS_URL=redis://localhost:6379/0
```

### Step 5: Initialize Database

```bash
python scripts/setup_database.py
```

---

## ğŸ¯ Quick Start

### Run Web Application

```bash
# Start the Flask web server
python -m essay_evaluator.api.app

# Access the application at:
# http://localhost:5000
```

### Command Line Usage

```python
from essay_evaluator.core.agent import EvaluadorEnsayos

# Initialize evaluator
evaluator = EvaluadorEnsayos()

# Evaluate an essay
with open('essay.txt', 'r') as f:
    essay_text = f.read()

evaluation = evaluator.evaluar(essay_text)
print(f"Score: {evaluation.puntuacion_total:.2f}/5.0")
```

### Batch Processing

```bash
# Evaluate all PDFs in a folder
python scripts/batch_evaluate.py --input pdfs/ --output results/
```

---

## ğŸ“– Usage

### Web Interface

1. **Login**: Access the system at `http://localhost:5000`
2. **Upload Essay**: Drag & drop PDF or use file selector
3. **View Results**: Review detailed evaluation with scores and feedback
4. **Compare Essays**: Select multiple essays for side-by-side comparison
5. **Export**: Download results as Excel or PDF report

### API Endpoints

#### Authentication
```bash
# Register user
POST /api/auth/register
{
  "username": "admin",
  "password": "secure_password"
}

# Login
POST /api/auth/login
{
  "username": "admin",
  "password": "secure_password"
}
```

#### Essay Evaluation
```bash
# Upload and evaluate essay
POST /api/essays/evaluate
Content-Type: multipart/form-data
Authorization: Bearer <token>

# Get essay by ID
GET /api/essays/{essay_id}
Authorization: Bearer <token>

# List all essays
GET /api/essays
Authorization: Bearer <token>

# Compare essays
POST /api/essays/compare
{
  "essay_ids": [1, 2, 3]
}
```

See [API Documentation](docs/api/endpoints.md) for complete reference.

---

## âš™ï¸ Configuration

### Evaluation Settings

Customize evaluation behavior in `config/development.py`:

```python
EVALUATION_CONFIG = {
    'model': 'gpt-4o',  # or 'gpt-4o-mini' for faster/cheaper
    'temperature': 0.3,
    'max_tokens': 2000,
    'parallel_execution': True,  # Enable parallel criterion evaluation
    'criteria_weights': {
        'calidad_tecnica': 0.167,
        'creatividad': 0.167,
        'vinculacion_tematica': 0.167,
        'bienestar_colectivo': 0.167,
        'uso_responsable_ia': 0.167,
        'potencial_impacto': 0.167
    }
}
```

### Performance Tuning

- **Caching**: Enable Redis for 10x faster repeat evaluations
- **Batch Size**: Adjust `BATCH_SIZE` for concurrent processing
- **Timeouts**: Configure `REQUEST_TIMEOUT` for long documents

---

## ğŸ§ª Testing

### Run All Tests

```bash
pytest
```

### Run Specific Test Suite

```bash
# Test agent
pytest essay_evaluator/tests/test_agent.py

# Test API
pytest essay_evaluator/tests/test_api.py -v

# Test with coverage
pytest --cov=essay_evaluator --cov-report=html
```

---

## ğŸ› ï¸ Development

### Install Development Dependencies

```bash
pip install -r requirements-dev.txt
```

### Code Quality

```bash
# Format code
black essay_evaluator/

# Lint code
flake8 essay_evaluator/

# Type checking
mypy essay_evaluator/
```

### Pre-commit Hooks

```bash
pre-commit install
pre-commit run --all-files
```

---

## ğŸ“Š Architecture

### System Components

1. **Core Agent**: LangGraph-based parallel evaluation engine
2. **API Layer**: RESTful Flask API with JWT authentication
3. **Web Interface**: Responsive SPA with vanilla JavaScript
4. **Database**: SQLite with SQLAlchemy ORM
5. **PDF Processor**: PyPDF + pdfplumber for text extraction

### Data Flow

```
PDF Upload â†’ Text Extraction â†’ Agent Evaluation â†’ Database Storage â†’ Report Generation
     â†“                             â†“
Validation                   Parallel Criteria
     â†“                       Processing (6 nodes)
Preprocessing                        â†“
                              Final Synthesis
```

See [Architecture Documentation](docs/architecture/system_design.md) for details.

---

## ğŸ¤ Contributing

Contributions are welcome! Please follow these steps:

1. Fork the repository
2. Create feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit changes (`git commit -m 'Add AmazingFeature'`)
4. Push to branch (`git push origin feature/AmazingFeature`)
5. Open Pull Request

Please ensure:
- All tests pass
- Code is formatted with Black
- Documentation is updated
- Type hints are added

---

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ‘¥ Authors

- **Vania Janet** - *Initial work* - [Vania-Janet](https://github.com/Vania-Janet)

---

## ğŸ™ Acknowledgments

- OpenAI for GPT-4 API
- LangChain team for excellent LLM framework
- Flask community for web framework
- All contributors and testers

---

## ğŸ“ Support

- **Issues**: [GitHub Issues](https://github.com/Vania-Janet/llm-essay-reviewer/issues)
- **Documentation**: [Full Documentation](docs/)
- **Email**: support@example.com

---

## ğŸ—ºï¸ Roadmap

- [ ] Add support for more document formats (DOCX, TXT)
- [ ] Implement multi-language support
- [ ] Add plagiarism detection
- [ ] Create mobile app
- [ ] Integrate more LLM providers (Anthropic, Cohere)
- [ ] Add advanced analytics dashboard
- [ ] Implement peer review workflow
- [ ] Export to LaTeX/Academic formats
